{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport numpy as np                                                                               # Importing numpy for Matrix Operations\nimport pandas as pd                                                                              # Importing pandas to read CSV files\nimport matplotlib.pyplot as plt                                                                  # Importting matplotlib for Plotting and visualizing images\nimport math                                                                                      # Importing math module to perform mathematical operations\nimport cv2                                                                                       # Importing openCV for image processing\nimport seaborn as sns \n\n\n# Tensorflow modules\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator                              # Importing the ImageDataGenerator for data augmentation\nfrom tensorflow.keras.models import Sequential                                                   # Importing the sequential module to define a sequential model\nfrom tensorflow.keras.layers import Dense,Dropout,Flatten,Conv2D,MaxPooling2D,BatchNormalization # Defining all the layers to build our CNN Model\nfrom tensorflow.keras.optimizers import Adam,SGD                                                 # Importing the optimizers which can be used in our model\nfrom sklearn import preprocessing                                                                # Importing the preprocessing module to preprocess the data\nfrom sklearn.model_selection import train_test_split                                             # Importing train_test_split function to split the data into train and test\nfrom sklearn.metrics import accuracy_score, confusion_matrix                                                     # Importing confusion_matrix to plot the confusion matrix\n\n# Display images using OpenCV\n#from google.colab.patches import cv2_imshow                                                    # Importing cv2_imshow from google.patches to display images\n\n\n# Ignore warnings\nimport warnings\nwarnings.filterwarnings('ignore')\n\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-05-17T14:52:26.88837Z","iopub.execute_input":"2023-05-17T14:52:26.888712Z","iopub.status.idle":"2023-05-17T14:52:26.899029Z","shell.execute_reply.started":"2023-05-17T14:52:26.888686Z","shell.execute_reply":"2023-05-17T14:52:26.896869Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"DATADIR = \"/kaggle/input/sad-and-happy-face-detection/data\"  # Path of data\nCATEGORIES = [\"happy\",\"sad\"]                                # Storing all the categories in categories variable\nIMG_SIZE=150  ","metadata":{"execution":{"iopub.status.busy":"2023-05-17T14:42:43.858546Z","iopub.execute_input":"2023-05-17T14:42:43.859217Z","iopub.status.idle":"2023-05-17T14:42:43.869254Z","shell.execute_reply.started":"2023-05-17T14:42:43.859183Z","shell.execute_reply":"2023-05-17T14:42:43.867644Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Creating 4 different lists to store the image names for each category by reading them from their respective directories. \nhappy_imgs = [fn for fn in os.listdir(f'{DATADIR}/{CATEGORIES[0]}') ]          # Looping over the path of each image from the happy directory\nsad_imgs = [fn for fn in os.listdir(f'{DATADIR}/{CATEGORIES[1]}')]            # Looping over the path of each image from the sad directory\n\n     \n\n\n# Ranodmly selecting 3 images from each category\nselect_happy = np.random.choice(happy_imgs, 3, replace = False)               \nselect_sad = np.random.choice(sad_imgs, 3, replace = False)\n","metadata":{"execution":{"iopub.status.busy":"2023-05-17T14:42:43.87086Z","iopub.execute_input":"2023-05-17T14:42:43.871503Z","iopub.status.idle":"2023-05-17T14:42:43.889157Z","shell.execute_reply.started":"2023-05-17T14:42:43.871469Z","shell.execute_reply":"2023-05-17T14:42:43.888293Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plotting 4 x 3 image matrix\nfig = plt.figure(figsize = (10,10))\n\n# Plotting three images from each of the four categories by looping through their path \nfor i in range(6):\n    if i < 3:\n        fp = f'{DATADIR}/{CATEGORIES[0]}/{select_happy[i]}'                    # Here datadir is a path to the training data and categories[0] indicate the first label bread and here we are looping over to take the three random images that we have stored in select_galo variable \n        label = 'Happy'                                                 \n    if i>=3 and i<6:\n        fp = f'{DATADIR}/{CATEGORIES[1]}/{select_sad[i-3]}'                   # Here datadir is a path to the training data and categories[1] indicate the second label soup and here we are looping over to take the three random images that we have stored in select_menin variable \n        label = 'Sad' \n    ax = fig.add_subplot(4, 3, i+1)\n    \n    # Plotting each image using load_img function\n    fn = tf.keras.preprocessing.image.load_img(fp,target_size = (150,150))\n    #fn = image.load_img(fp, target_size = (150,150))\n    plt.imshow(fn, cmap='Greys_r')\n    plt.title(label)\n    plt.axis('off')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-05-17T14:42:43.891245Z","iopub.execute_input":"2023-05-17T14:42:43.891607Z","iopub.status.idle":"2023-05-17T14:42:44.394157Z","shell.execute_reply.started":"2023-05-17T14:42:43.891576Z","shell.execute_reply":"2023-05-17T14:42:44.393265Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data Preprocessing","metadata":{}},{"cell_type":"code","source":"# Here we will be using a user defined function create_training_data() to extract the images from the directory\ndata = []                                                             # Storing all the training images\ndef create_data():\n    for category in CATEGORIES:                                                # Looping over each category from the CATEGORIES list\n        path = os.path.join(DATADIR,category)                                  # Joining images with labels\n        class_num = category                                                   \n        for img in os.listdir(path):                                           \n          img_array = cv2.imread(os.path.join(path,img))                       # Reading the data\n          new_array = cv2.resize(img_array,(IMG_SIZE,IMG_SIZE))                # Resizing the images \n          data.append([new_array,class_num])                          # Appending both the images and labels\ncreate_data() ","metadata":{"execution":{"iopub.status.busy":"2023-05-17T14:42:44.395579Z","iopub.execute_input":"2023-05-17T14:42:44.39608Z","iopub.status.idle":"2023-05-17T14:42:59.966055Z","shell.execute_reply.started":"2023-05-17T14:42:44.396048Z","shell.execute_reply":"2023-05-17T14:42:59.965052Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Creating two different lists to store the Numpy arrays and the corresponding labels\nimages = []                                                                   \nlabels = []\nnp.random.shuffle(data)                                               # Shuffling data to reduce variance and making sure that model remains general and overfit less\nfor features,label in data:                                           # Iterating over the training data which is generated from the create_training_data() function \n    images.append(features)                                                   # Appending images into X_train\n    labels.append(label) ","metadata":{"execution":{"iopub.status.busy":"2023-05-17T14:42:59.969986Z","iopub.execute_input":"2023-05-17T14:42:59.970326Z","iopub.status.idle":"2023-05-17T14:42:59.978408Z","shell.execute_reply.started":"2023-05-17T14:42:59.970283Z","shell.execute_reply":"2023-05-17T14:42:59.97694Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Converting the list into DataFrame\nlabels = pd.DataFrame(labels, columns=[\"Label\"],dtype=object) \n","metadata":{"execution":{"iopub.status.busy":"2023-05-17T14:42:59.980045Z","iopub.execute_input":"2023-05-17T14:42:59.980415Z","iopub.status.idle":"2023-05-17T14:42:59.98786Z","shell.execute_reply.started":"2023-05-17T14:42:59.980383Z","shell.execute_reply":"2023-05-17T14:42:59.98694Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## EDA","metadata":{}},{"cell_type":"markdown","source":"**Checking for Data Imbalance**","metadata":{}},{"cell_type":"code","source":"# Storing the value counts of target variable\ncount=labels.Label.value_counts()\nprint(count)\nprint('*'*10)\ncount=labels.Label.value_counts(normalize=True)\nprint(count)","metadata":{"execution":{"iopub.status.busy":"2023-05-17T14:42:59.989817Z","iopub.execute_input":"2023-05-17T14:42:59.990494Z","iopub.status.idle":"2023-05-17T14:43:00.002868Z","shell.execute_reply.started":"2023-05-17T14:42:59.990456Z","shell.execute_reply":"2023-05-17T14:43:00.001987Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.histplot(labels['Label'])\nplt.xticks(rotation='vertical')","metadata":{"execution":{"iopub.status.busy":"2023-05-17T14:43:00.004565Z","iopub.execute_input":"2023-05-17T14:43:00.004872Z","iopub.status.idle":"2023-05-17T14:43:00.215081Z","shell.execute_reply.started":"2023-05-17T14:43:00.004829Z","shell.execute_reply":"2023-05-17T14:43:00.214171Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Converting the pixel values into Numpy array\nimages= np.array(images) \n","metadata":{"execution":{"iopub.status.busy":"2023-05-17T14:43:00.216894Z","iopub.execute_input":"2023-05-17T14:43:00.217573Z","iopub.status.idle":"2023-05-17T14:43:00.265726Z","shell.execute_reply.started":"2023-05-17T14:43:00.217538Z","shell.execute_reply":"2023-05-17T14:43:00.264722Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"images.shape","metadata":{"execution":{"iopub.status.busy":"2023-05-17T14:43:00.270171Z","iopub.execute_input":"2023-05-17T14:43:00.27049Z","iopub.status.idle":"2023-05-17T14:43:00.279398Z","shell.execute_reply.started":"2023-05-17T14:43:00.270465Z","shell.execute_reply":"2023-05-17T14:43:00.278224Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Visualizing images using Gaussian Blur ","metadata":{}},{"cell_type":"code","source":"# Applying Gaussian Blur to denoise the images\nimages_gb=[]\nfor i in range(len(images)):\n  # gb[i] = cv2.cvtColor(images[i], cv2.COLOR_BGR2RGB)\n  images_gb.append(cv2.GaussianBlur(images[i], ksize =(3,3),sigmaX =  0))","metadata":{"execution":{"iopub.status.busy":"2023-05-17T14:43:00.28117Z","iopub.execute_input":"2023-05-17T14:43:00.281603Z","iopub.status.idle":"2023-05-17T14:43:00.40759Z","shell.execute_reply.started":"2023-05-17T14:43:00.28157Z","shell.execute_reply":"2023-05-17T14:43:00.406498Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.imshow(images_gb[140])","metadata":{"execution":{"iopub.status.busy":"2023-05-17T14:43:00.409231Z","iopub.execute_input":"2023-05-17T14:43:00.409891Z","iopub.status.idle":"2023-05-17T14:43:00.719107Z","shell.execute_reply.started":"2023-05-17T14:43:00.409855Z","shell.execute_reply":"2023-05-17T14:43:00.718015Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- It appears that GaussianBlur can be effective because the blurred or denoised image does not seem to remove any relevant information.","metadata":{}},{"cell_type":"markdown","source":"## **Splitting the dataset**\n\n- We will only use 10% of our data for testing, 10% of our data for validation and 80% of our data for training.\n- We are using the train_test_split() function from scikit-learn. Here, we split the dataset into three parts, train,test and validation.","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_temp, X_test, y_temp, y_test = train_test_split(np.array(images_gb),labels , test_size=0.1, random_state=42,stratify=labels)\nX_train, X_val, y_train, y_val = train_test_split(X_temp,y_temp , test_size=0.1, random_state=42,stratify=y_temp)","metadata":{"execution":{"iopub.status.busy":"2023-05-17T14:43:00.721763Z","iopub.execute_input":"2023-05-17T14:43:00.722054Z","iopub.status.idle":"2023-05-17T14:43:00.872085Z","shell.execute_reply.started":"2023-05-17T14:43:00.722026Z","shell.execute_reply":"2023-05-17T14:43:00.870928Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_train.head()","metadata":{"execution":{"iopub.status.busy":"2023-05-17T14:43:00.873805Z","iopub.execute_input":"2023-05-17T14:43:00.874181Z","iopub.status.idle":"2023-05-17T14:43:00.883023Z","shell.execute_reply.started":"2023-05-17T14:43:00.874147Z","shell.execute_reply":"2023-05-17T14:43:00.881914Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(X_train.shape,y_train.shape)\nprint(X_val.shape,y_val.shape)\nprint(X_test.shape,y_test.shape)","metadata":{"execution":{"iopub.status.busy":"2023-05-17T14:43:00.884499Z","iopub.execute_input":"2023-05-17T14:43:00.885077Z","iopub.status.idle":"2023-05-17T14:43:00.893959Z","shell.execute_reply.started":"2023-05-17T14:43:00.885044Z","shell.execute_reply":"2023-05-17T14:43:00.892865Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data Normalization","metadata":{}},{"cell_type":"code","source":"# Normalizing the image pixels\nX_train_normalized = X_train.astype('float32')/255.0\nX_val_normalized = X_val.astype('float32')/255.0\nX_test_normalized = X_test.astype('float32')/255.0","metadata":{"execution":{"iopub.status.busy":"2023-05-17T14:43:00.895197Z","iopub.execute_input":"2023-05-17T14:43:00.89582Z","iopub.status.idle":"2023-05-17T14:43:01.081046Z","shell.execute_reply.started":"2023-05-17T14:43:00.895747Z","shell.execute_reply":"2023-05-17T14:43:01.080061Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(X_train_normalized.shape,y_train.shape)\nprint(X_val.shape,y_val.shape)\nprint(X_test.shape,y_test.shape)","metadata":{"execution":{"iopub.status.busy":"2023-05-17T14:43:01.082748Z","iopub.execute_input":"2023-05-17T14:43:01.083131Z","iopub.status.idle":"2023-05-17T14:43:01.089372Z","shell.execute_reply.started":"2023-05-17T14:43:01.083098Z","shell.execute_reply":"2023-05-17T14:43:01.088369Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **Encoding Target Variable**","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import LabelBinarizer\nenc = LabelBinarizer()\ny_train_encoded = enc.fit_transform(y_train)\ny_val_encoded=enc.transform(y_val)\ny_test_encoded=enc.transform(y_test)","metadata":{"execution":{"iopub.status.busy":"2023-05-17T14:43:01.091018Z","iopub.execute_input":"2023-05-17T14:43:01.091361Z","iopub.status.idle":"2023-05-17T14:43:01.125557Z","shell.execute_reply.started":"2023-05-17T14:43:01.091329Z","shell.execute_reply":"2023-05-17T14:43:01.1245Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(X_train.shape,y_train_encoded.shape)\n","metadata":{"execution":{"iopub.status.busy":"2023-05-17T14:43:01.127102Z","iopub.execute_input":"2023-05-17T14:43:01.127453Z","iopub.status.idle":"2023-05-17T14:43:01.133361Z","shell.execute_reply.started":"2023-05-17T14:43:01.127421Z","shell.execute_reply":"2023-05-17T14:43:01.132205Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = Sequential()","metadata":{"execution":{"iopub.status.busy":"2023-05-17T14:43:01.134739Z","iopub.execute_input":"2023-05-17T14:43:01.135287Z","iopub.status.idle":"2023-05-17T14:43:01.146954Z","shell.execute_reply.started":"2023-05-17T14:43:01.135253Z","shell.execute_reply":"2023-05-17T14:43:01.145964Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.add(Conv2D(16, (3,3), 1, activation='relu', input_shape=(150,150,3)))\n\n# Adding max pooling to reduce the size of output of first conv layer\nmodel.add(MaxPooling2D((2, 2), padding = 'same'))\n\nmodel.add(Conv2D(32, (3, 3), activation='relu', padding=\"same\"))\nmodel.add(MaxPooling2D((2, 2), padding = 'same'))\nmodel.add(Conv2D(32, (3, 3), activation='relu', padding=\"same\"))\nmodel.add(MaxPooling2D((2, 2), padding = 'same'))\n\nmodel.add(Flatten())\n# Adding a fully connected dense layer with 100 neurons    \nmodel.add(Dense(256, activation='relu'))\n\nmodel.add(Dense(1, activation='sigmoid'))","metadata":{"execution":{"iopub.status.busy":"2023-05-17T14:43:01.14847Z","iopub.execute_input":"2023-05-17T14:43:01.148799Z","iopub.status.idle":"2023-05-17T14:43:01.270363Z","shell.execute_reply.started":"2023-05-17T14:43:01.148769Z","shell.execute_reply":"2023-05-17T14:43:01.269171Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile('adam',loss = tf.losses.BinaryCrossentropy(), metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2023-05-17T14:43:01.275234Z","iopub.execute_input":"2023-05-17T14:43:01.275946Z","iopub.status.idle":"2023-05-17T14:43:01.295143Z","shell.execute_reply.started":"2023-05-17T14:43:01.275909Z","shell.execute_reply":"2023-05-17T14:43:01.293766Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2023-05-17T14:43:01.300587Z","iopub.execute_input":"2023-05-17T14:43:01.301151Z","iopub.status.idle":"2023-05-17T14:43:01.359395Z","shell.execute_reply.started":"2023-05-17T14:43:01.301091Z","shell.execute_reply":"2023-05-17T14:43:01.358685Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history_1 = model.fit(\n            X_train_normalized, y_train_encoded,\n            epochs=30,\n            validation_data=(X_val_normalized,y_val_encoded),\n            batch_size=16,\n            verbose=2\n)","metadata":{"execution":{"iopub.status.busy":"2023-05-17T14:43:01.360471Z","iopub.execute_input":"2023-05-17T14:43:01.361001Z","iopub.status.idle":"2023-05-17T14:43:43.996971Z","shell.execute_reply.started":"2023-05-17T14:43:01.360969Z","shell.execute_reply":"2023-05-17T14:43:43.995891Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(history_1.history['accuracy'])\nplt.plot(history_1.history['val_accuracy'])\nplt.title('Model Accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Validation'], loc='upper left')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-05-17T14:43:44.002816Z","iopub.execute_input":"2023-05-17T14:43:44.004882Z","iopub.status.idle":"2023-05-17T14:43:44.252158Z","shell.execute_reply.started":"2023-05-17T14:43:44.004852Z","shell.execute_reply":"2023-05-17T14:43:44.251238Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"accuracy = model.evaluate(X_val_normalized, y_val_encoded, verbose=2)","metadata":{"execution":{"iopub.status.busy":"2023-05-17T14:47:55.579541Z","iopub.execute_input":"2023-05-17T14:47:55.579924Z","iopub.status.idle":"2023-05-17T14:47:55.747853Z","shell.execute_reply.started":"2023-05-17T14:47:55.579894Z","shell.execute_reply":"2023-05-17T14:47:55.746961Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Val Prediction \ny_val_pred_ln = model.predict(X_val)\ny_val_pred_classes_ln = np.argmax(y_val_pred_ln, axis=1)\nnormal_y_val = np.argmax(y_val_encoded, axis=1)","metadata":{"execution":{"iopub.status.busy":"2023-05-17T14:48:56.290525Z","iopub.execute_input":"2023-05-17T14:48:56.290881Z","iopub.status.idle":"2023-05-17T14:48:56.424745Z","shell.execute_reply.started":"2023-05-17T14:48:56.290852Z","shell.execute_reply":"2023-05-17T14:48:56.423767Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# val Accuracy \naccuracy_score((normal_y_val), y_val_pred_classes_ln)","metadata":{"execution":{"iopub.status.busy":"2023-05-17T14:49:27.166255Z","iopub.execute_input":"2023-05-17T14:49:27.166645Z","iopub.status.idle":"2023-05-17T14:49:27.175958Z","shell.execute_reply.started":"2023-05-17T14:49:27.166615Z","shell.execute_reply":"2023-05-17T14:49:27.174766Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"accuracy = model.evaluate(X_test_normalized, y_test_encoded, verbose=2)","metadata":{"execution":{"iopub.status.busy":"2023-05-17T14:43:44.253675Z","iopub.execute_input":"2023-05-17T14:43:44.254063Z","iopub.status.idle":"2023-05-17T14:43:44.477736Z","shell.execute_reply.started":"2023-05-17T14:43:44.254027Z","shell.execute_reply":"2023-05-17T14:43:44.476813Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Test Prediction \ny_test_pred_ln = model.predict(X_test)\ny_test_pred_classes_ln = np.argmax(y_test_pred_ln, axis=1)\nnormal_y_test = np.argmax(y_test_encoded, axis=1)","metadata":{"execution":{"iopub.status.busy":"2023-05-17T14:43:44.479179Z","iopub.execute_input":"2023-05-17T14:43:44.479538Z","iopub.status.idle":"2023-05-17T14:43:44.642336Z","shell.execute_reply.started":"2023-05-17T14:43:44.479504Z","shell.execute_reply":"2023-05-17T14:43:44.641338Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Test Accuracy \naccuracy_score((normal_y_test), y_test_pred_classes_ln)","metadata":{"execution":{"iopub.status.busy":"2023-05-17T14:45:22.227323Z","iopub.execute_input":"2023-05-17T14:45:22.227917Z","iopub.status.idle":"2023-05-17T14:45:22.235753Z","shell.execute_reply.started":"2023-05-17T14:45:22.227884Z","shell.execute_reply":"2023-05-17T14:45:22.234684Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Test Accuracy \naccuracy_score((normal_y_test), y_test_pred_classes_ln)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cf_matrix = confusion_matrix(normal_y_test, y_test_pred_classes_ln)\n\n# Confusion matrix normalized per category true value\ncf_matrix_n1 = cf_matrix/np.sum(cf_matrix, axis=1)\nplt.figure(figsize=(8,6))\nsns.heatmap(cf_matrix_n1, xticklabels=CATEGORIES, yticklabels=CATEGORIES, annot=True)","metadata":{"execution":{"iopub.status.busy":"2023-05-17T14:45:37.916256Z","iopub.execute_input":"2023-05-17T14:45:37.91695Z","iopub.status.idle":"2023-05-17T14:45:38.576263Z","shell.execute_reply.started":"2023-05-17T14:45:37.916915Z","shell.execute_reply":"2023-05-17T14:45:38.575239Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import classification_report\nprint(classification_report((normal_y_test), y_test_pred_classes_ln))","metadata":{"execution":{"iopub.status.busy":"2023-05-17T14:50:43.720062Z","iopub.execute_input":"2023-05-17T14:50:43.720463Z","iopub.status.idle":"2023-05-17T14:50:43.734614Z","shell.execute_reply.started":"2023-05-17T14:50:43.72043Z","shell.execute_reply":"2023-05-17T14:50:43.73366Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Visualizing the predicted and correct label of images from test data\nplt.figure(figsize=(2,2))\nplt.imshow(X_test[0])\nplt.show()\nprint('Predicted Label', enc.inverse_transform(model.predict((X_test_normalized[0].reshape(1,150,150,3)))))   # reshaping the input image as we are only trying to predict using a single image\nprint('True Label', enc.inverse_transform(y_test_encoded)[0])                                               # using inverse_transform() to get the output label from the output vector\n\n# Visualizing the predicted and correct label of images from test data\nplt.figure(figsize=(2,2))\nplt.imshow(X_test[22])\nplt.show()\nprint('Predicted Label', enc.inverse_transform(model.predict((X_test_normalized[22].reshape(1,150,150,3)))))   # reshaping the input image as we are only trying to predict using a single image\nprint('True Label', enc.inverse_transform(y_test_encoded)[22])                                               # using inverse_transform() to get the output label from the output vector\n\n# Visualizing the predicted and correct label of images from test data\nplt.figure(figsize=(2,2))\nplt.imshow(X_test[11])\nplt.show()\nprint('Predicted Label', enc.inverse_transform(model.predict((X_test_normalized[11].reshape(1,150,150,3)))))   # reshaping the input image as we are only trying to predict using a single image\nprint('True Label', enc.inverse_transform(y_test_encoded)[11])                                               # using inverse_transform() to get the output label from the output vector\n","metadata":{"execution":{"iopub.status.busy":"2023-05-17T14:59:39.491055Z","iopub.execute_input":"2023-05-17T14:59:39.491454Z","iopub.status.idle":"2023-05-17T14:59:40.148986Z","shell.execute_reply.started":"2023-05-17T14:59:39.49142Z","shell.execute_reply":"2023-05-17T14:59:40.148067Z"},"trusted":true},"execution_count":null,"outputs":[]}]}